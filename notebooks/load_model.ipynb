{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-28 05:06:07.319089: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-28 05:06:07.468011: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-06-28 05:06:08.855139: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.1/lib64:/usr/local/cuda-12.1/lib64:/usr/local/cuda-12.1/lib64:\n",
      "2023-06-28 05:06:08.855238: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.1/lib64:/usr/local/cuda-12.1/lib64:/usr/local/cuda-12.1/lib64:\n",
      "2023-06-28 05:06:08.855245: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/home/ubuntu/.pyenv/versions/3.9.13/envs/asgard/lib/python3.9/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import wandb\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import numpy as np\n",
    "from official.nlp import optimization\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "from asgard.utils.data_loader import load_datasets\n",
    "from asgard.callbacks.callbacks import EarlyStoppingHammingScore\n",
    "from asgard.metrics.metrics import HammingScoreMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_weight(train_set, class_weight_kind=\"balanced\"):\n",
    "  if (class_weight_kind is None) or (class_weight_kind == \"None\"):\n",
    "    class_weights = None\n",
    "\n",
    "  elif class_weight_kind == \"balanced\":\n",
    "    class_weights = compute_class_weights(train_set)\n",
    "\n",
    "  elif class_weight_kind == \"two-to-one\":\n",
    "    class_weights = np.zeros((16, 2))\n",
    "    class_weights[:, 0] = 1.0\n",
    "    class_weights[:, 1] = 2.0\n",
    "\n",
    "  return class_weights\n",
    "\n",
    "\n",
    "def get_weighted_loss(weights):\n",
    "  def weighted_loss(y_train, y_pred):\n",
    "    return keras.backend.mean(\n",
    "      (weights[:, 0] ** (1 - y_train))\n",
    "      * (weights[:, 1] ** y_train)\n",
    "      * keras.backend.binary_crossentropy(y_train, y_pred),\n",
    "      axis=-1,\n",
    "    )\n",
    "\n",
    "  return weighted_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-06-28 05:06:10] absl - INFO: using Adamw optimizer\n",
      "[2023-06-28 05:06:10] absl - INFO: AdamWeightDecay gradient_clip_norm=1.000000\n"
     ]
    }
   ],
   "source": [
    "# Define number of epochs\n",
    "epochs = 4\n",
    "steps_per_epoch = 24813 # tf.data.experimental.cardinality(train_set).numpy()\n",
    "\n",
    "# Define optimizer\n",
    "num_train_steps = steps_per_epoch * epochs\n",
    "num_warmup_steps = int(0.05 * num_train_steps)\n",
    "\n",
    "init_lr = 3e-5\n",
    "optimizer = optimization.create_optimizer(init_lr=init_lr,\n",
    "                                          num_train_steps=num_train_steps,\n",
    "                                          num_warmup_steps=num_warmup_steps,\n",
    "                                          optimizer_type='adamw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu/git/asgard/notebooks'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfhub_encoder_handler = \"https://tfhub.dev/jeongukjae/distilbert_en_uncased_L-6_H-768_A-12/1\"\n",
    "tfhub_preprocess_handler = \"https://tfhub.dev/jeongukjae/distilbert_en_uncased_preprocess/2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-28 05:06:15.492431: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-28 05:06:15.582099: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-28 05:06:15.584927: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-28 05:06:15.587747: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-28 05:06:15.588202: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-28 05:06:15.590830: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-28 05:06:15.593189: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-28 05:06:16.448489: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-28 05:06:16.450239: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-28 05:06:16.451712: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-28 05:06:16.453088: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13633 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "train_set, valid_set, test_set = load_datasets(\"../storage/datasets/tf_raw\")\n",
    "\n",
    "subsample_size = 100\n",
    "\n",
    "# Shuffle the dataset\n",
    "test_shuffled_dataset = test_set.shuffle(buffer_size=100)\n",
    "\n",
    "# Take a subsample from the shuffled dataset\n",
    "test_subsample = test_shuffled_dataset.take(subsample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-06-28 05:06:26] wandb.jupyter - ERROR: Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandre-hsd\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/git/asgard/notebooks/wandb/run-20230628_050627-vj1a1i3f</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/alexandre-hsd/asgard-notebooks/runs/vj1a1i3f' target=\"_blank\">exalted-plant-1</a></strong> to <a href='https://wandb.ai/alexandre-hsd/asgard-notebooks' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/alexandre-hsd/asgard-notebooks' target=\"_blank\">https://wandb.ai/alexandre-hsd/asgard-notebooks</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/alexandre-hsd/asgard-notebooks/runs/vj1a1i3f' target=\"_blank\">https://wandb.ai/alexandre-hsd/asgard-notebooks/runs/vj1a1i3f</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact model-vibrant-sweep-14:v2, 772.98MB. 6 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   6 of 6 files downloaded.  \n",
      "Done. 0:0:4.4\n"
     ]
    }
   ],
   "source": [
    "run = wandb.init()\n",
    "artifact = run.use_artifact('alexandre-hsd/ASGARD-DistilBERT/model-vibrant-sweep-14:v2', type='model')\n",
    "artifact_dir = artifact.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./artifacts/model-vibrant-sweep-14:v2'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artifact_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-06-28 05:07:43] absl - INFO: using Adamw optimizer\n",
      "[2023-06-28 05:07:43] absl - INFO: AdamWeightDecay gradient_clip_norm=1.000000\n",
      "[2023-06-28 05:07:59] absl - INFO: AdamWeightDecay gradient_clip_norm=1.000000\n"
     ]
    }
   ],
   "source": [
    "target_folder = './artifacts/model-vibrant-sweep-14:v2'\n",
    "\n",
    "weights = np.zeros((16, 2))\n",
    "weights[:, 0] = 1.\n",
    "weights[:, 1] = 2.\n",
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.PolynomialDecay(\n",
    "    initial_learning_rate=init_lr,\n",
    "    decay_steps=num_train_steps,\n",
    "    end_learning_rate=0.0,\n",
    "    power=1.0)\n",
    "\n",
    "model = tf.keras.models.load_model(target_folder,\n",
    "                                   custom_objects={\"weighted_loss\": get_weighted_loss(weights),\n",
    "                                                   \"AdamWeightDecay\": optimization.create_optimizer(init_lr=init_lr,\n",
    "                                                                                                    num_train_steps=num_train_steps,\n",
    "                                                                                                    num_warmup_steps=num_warmup_steps,\n",
    "                                                                                                    optimizer_type='adamw'),\n",
    "                                                   \"WarmUp\": optimization.WarmUp(initial_learning_rate=init_lr,\n",
    "                                                                                 decay_schedule_fn=lr_schedule,\n",
    "                                                                                 warmup_steps=num_warmup_steps),\n",
    "                                                   \"HammingScoreMetric\": HammingScoreMetric()}\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 17s 149ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_subsample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99002004, 0.13448282, 0.568767  , 0.24128814, 0.5312531 ,\n",
       "       0.13886882, 0.00776579, 0.56381345, 0.0501148 , 0.96482897,\n",
       "       0.40658736, 0.04535012, 0.08588963, 0.0132065 , 0.04039462,\n",
       "       0.3102229 ], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.47885454, 0.09220963, 0.28528795, 0.2871287 , 0.10069013,\n",
       "       0.09461151, 0.06952499, 0.45123702, 0.33866397, 0.4710489 ,\n",
       "       0.13410343, 0.6900652 , 0.29761913, 0.0959122 , 0.12628393,\n",
       "       0.90638286], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.09356621, 0.08309215, 0.13621739, 0.04193821, 0.05000394,\n",
       "       0.29958984, 0.03654183, 0.10060693, 0.0481165 , 0.0402372 ,\n",
       "       0.790424  , 0.18693845, 0.5943945 , 0.930888  , 0.3253251 ,\n",
       "       0.03340747], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.3458106 , 0.06801132, 0.0663984 , 0.1316111 , 0.12827072,\n",
       "       0.08205006, 0.16548498, 0.8244478 , 0.89248174, 0.73548937,\n",
       "       0.05578999, 0.9792474 , 0.27790752, 0.12828353, 0.5777957 ,\n",
       "       0.33591527], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'COVID-19: Lessons for junior doctors redeployed to critical care', shape=(), dtype=string) tf.Tensor([0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(16,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "first_element = next(iter(test_subsample.take(1)))\n",
    "print(first_element[0][0], first_element[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asgard",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
